{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,MaxPooling2D,Dense,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if you have tensorflow version more than 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset for the code. Assign the training and testing data directory in the variables train_dir and test_dir respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'maskdata/train/'\n",
    "test_dir = 'maskdata/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to initialize ImageDataGenerators so as to rescale the images. The original images consist of RGB pixel value in the range 0-255. These values are too high for the model to process. Thus by dividing the pixel values by 255 brings each value in the range 0-1 which is smaller and easier to work upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1/255.0)\n",
    "test = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the images from the dataset and to classify each image according to the folder in which they are stored, we use the 'flow_from_directory' method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1207 images belonging to 2 classes.\n",
      "Found 334 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train.flow_from_directory(train_dir, target_size = (200,200),  class_mode ='binary')\n",
    "test_dataset = test.flow_from_directory(test_dir, target_size = (200,200),  class_mode ='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data and classified them, we design out model for the prediction. We use the activation function 'sigmoid' since we have to make classification into two classes : namely withmask and withoutmask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(200 , 200, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to use callbacks in our code. A callback is used during model fitting. When we reach an epoch with the mentioned value in the callback function, the model training stops even if some epochs are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(logs.get('accuracy'))\n",
    "        if(logs.get('accuracy')>0.96):\n",
    "            print(\"\\nReached 96% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 38 steps, validate for 11 steps\n",
      "Epoch 1/20\n",
      "37/38 [============================>.] - ETA: 4s - loss: 0.7374 - accuracy: 0.78890.7945319\n",
      "38/38 [==============================] - 178s 5s/step - loss: 0.7199 - accuracy: 0.7945 - val_loss: 0.1502 - val_accuracy: 0.9461\n",
      "Epoch 2/20\n",
      "37/38 [============================>.] - ETA: 4s - loss: 0.1109 - accuracy: 0.95740.956918\n",
      "38/38 [==============================] - 175s 5s/step - loss: 0.1109 - accuracy: 0.9569 - val_loss: 0.1116 - val_accuracy: 0.9581\n",
      "Epoch 3/20\n",
      "37/38 [============================>.] - ETA: 4s - loss: 0.0929 - accuracy: 0.96940.968517\n",
      "\n",
      "Reached 96% accuracy so cancelling training!\n",
      "38/38 [==============================] - 173s 5s/step - loss: 0.0941 - accuracy: 0.9685 - val_loss: 0.1099 - val_accuracy: 0.9551\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, \n",
    "                    epochs=20, \n",
    "                    validation_data=test_dataset ,\n",
    "                    callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model and have a permissible accuracy of our model, we can predict on on images ,videos or use our webcam for prediction on live video streaming. But we need to preprocess them before predicting.We rescale and reshape the images. Here we are using a video and predicting on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepImg(data):\n",
    "    return cv2.resize(data,(200,200)).reshape(200,200,3)/255.0\n",
    " \n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9878996]]\n",
      "[[0.9889389]]\n",
      "[[0.9889389]]\n",
      "[[0.9878198]]\n",
      "[[0.9889971]]\n",
      "[[0.9892363]]\n",
      "[[0.9875935]]\n",
      "[[0.9843419]]\n",
      "[[0.9866368]]\n",
      "[[0.9845307]]\n",
      "[[0.9855606]]\n",
      "[[0.9882443]]\n",
      "[[0.9834661]]\n",
      "[[0.98415035]]\n",
      "[[0.9920729]]\n",
      "[[0.99086785]]\n",
      "[[0.98941433]]\n",
      "[[0.98422235]]\n",
      "[[0.9798078]]\n",
      "[[0.98331636]]\n",
      "[[0.9831313]]\n",
      "[[0.98496675]]\n",
      "[[0.9843774]]\n",
      "[[0.48884788]]\n",
      "[[0.9808498]]\n",
      "[[0.9809724]]\n",
      "[[0.98407066]]\n",
      "[[0.9772027]]\n",
      "[[0.9818107]]\n",
      "[[0.9843241]]\n",
      "[[0.99085355]]\n",
      "[[0.990836]]\n",
      "[[0.9913667]]\n",
      "[[0.98919606]]\n",
      "[[0.9870962]]\n",
      "[[0.9856952]]\n",
      "[[0.98475236]]\n",
      "[[0.9845889]]\n",
      "[[0.97137535]]\n",
      "[[0.9631478]]\n",
      "[[0.00854731]]\n",
      "[[0.7416767]]\n",
      "[[0.52907777]]\n",
      "[[0.16700062]]\n",
      "[[0.0239353]]\n",
      "[[0.01590835]]\n",
      "[[0.00619407]]\n",
      "[[0.0038557]]\n",
      "[[0.00294279]]\n",
      "[[0.00206496]]\n",
      "[[0.00290489]]\n",
      "[[0.01025569]]\n",
      "[[0.01682397]]\n",
      "[[0.01054952]]\n",
      "[[0.01967985]]\n",
      "[[0.02188615]]\n",
      "[[0.01136669]]\n",
      "[[0.01046958]]\n",
      "[[0.00612592]]\n",
      "[[0.00333974]]\n",
      "[[0.00363969]]\n",
      "[[0.00225341]]\n",
      "[[0.00206323]]\n",
      "[[0.00084951]]\n",
      "[[0.00129448]]\n",
      "[[0.00115637]]\n",
      "[[0.00149582]]\n",
      "[[0.02169397]]\n",
      "[[0.00623027]]\n",
      "[[0.00104494]]\n",
      "[[0.0016304]]\n",
      "[[0.00240039]]\n",
      "[[0.00223444]]\n",
      "[[0.00171731]]\n",
      "[[0.00161468]]\n",
      "[[0.00159661]]\n",
      "[[0.00163104]]\n",
      "[[0.00174095]]\n",
      "[[0.00114805]]\n",
      "[[0.00108342]]\n",
      "[[0.00084384]]\n",
      "[[0.001038]]\n",
      "[[0.00112144]]\n",
      "[[0.00112348]]\n",
      "[[0.8875027]]\n",
      "[[0.00126986]]\n",
      "[[0.00107117]]\n",
      "[[0.00100302]]\n",
      "[[0.00112185]]\n",
      "[[0.00104908]]\n",
      "[[0.00156555]]\n",
      "[[0.00118666]]\n",
      "[[0.00159284]]\n",
      "[[0.00252366]]\n",
      "[[0.00276617]]\n",
      "[[0.00332394]]\n",
      "[[0.00243032]]\n",
      "[[0.00225408]]\n",
      "[[0.0030174]]\n",
      "[[0.00401958]]\n",
      "[[0.00444458]]\n",
      "[[0.00313968]]\n",
      "[[0.00361453]]\n",
      "[[0.00310596]]\n",
      "[[0.00383695]]\n",
      "[[0.00559842]]\n",
      "[[0.00373691]]\n",
      "[[0.00377555]]\n",
      "[[0.00127463]]\n",
      "[[0.00143191]]\n",
      "[[0.0022889]]\n",
      "[[0.00208185]]\n",
      "[[0.00396443]]\n",
      "[[0.00099606]]\n",
      "[[0.00051853]]\n",
      "[[0.00042547]]\n",
      "[[0.36088854]]\n",
      "[[0.00450257]]\n",
      "[[0.00098131]]\n",
      "[[0.00198567]]\n",
      "[[0.00538137]]\n",
      "[[0.0068571]]\n",
      "[[0.05205195]]\n",
      "[[0.04938357]]\n",
      "[[0.18771589]]\n",
      "[[0.00481898]]\n",
      "[[0.00392172]]\n",
      "[[0.01195592]]\n",
      "[[0.12819341]]\n",
      "[[0.27811933]]\n",
      "[[0.6071074]]\n",
      "[[0.9224116]]\n",
      "[[0.6416557]]\n",
      "[[0.8545941]]\n",
      "[[0.8614358]]\n",
      "[[0.94894207]]\n",
      "[[0.00981554]]\n",
      "[[0.9266562]]\n",
      "[[0.954513]]\n",
      "[[0.9702794]]\n",
      "[[0.96143204]]\n",
      "[[0.9683616]]\n",
      "[[0.9792197]]\n",
      "[[0.97637093]]\n",
      "[[0.97745126]]\n",
      "[[0.97170097]]\n",
      "[[0.9749136]]\n",
      "[[0.9768355]]\n",
      "[[0.97457916]]\n",
      "[[0.9797631]]\n",
      "[[0.9739299]]\n",
      "[[0.9775934]]\n",
      "[[0.9793519]]\n"
     ]
    }
   ],
   "source": [
    "cap =cv2.VideoCapture(\"fast.mp4\")\n",
    "if (cap.isOpened()== False):  \n",
    "    print(\"Error opening video  file\") \n",
    "    \n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(gray)\n",
    "    for (x,y,w,h) in faces :\n",
    "        sliced = frame[y:y+h,x:x+w]\n",
    "        sliced = prepImg(sliced)\n",
    "        sliced = np.expand_dims(sliced , axis = 0)\n",
    "        pred = model.predict(sliced)\n",
    "        print(pred)\n",
    "        if pred <0.5:\n",
    "            cv2.rectangle(frame , (x,y) , (x+w,y+h) , (0,0,255) , 3)\n",
    "            cv2.putText(frame, 'NO MASK', (x,y), cv2.FONT_HERSHEY_SIMPLEX ,  1, (0,0,255) , 2, cv2.LINE_AA) \n",
    "        else :\n",
    "            cv2.rectangle(frame , (x,y) , (x+w,y+h) , (0,255,0) , 3)    \n",
    "            cv2.putText(frame, 'MASK', (x,y), cv2.FONT_HERSHEY_SIMPLEX ,  1, (0,255,0) , 2, cv2.LINE_AA) \n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
